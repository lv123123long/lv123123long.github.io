---
title: 评估LLM
pubDate: 2024-09-16
categories: ['LLM']
description: ''
---

# 评估LLM

## 基础标准

1. Open LLM Leaderboard 是目前最流行的LLM评测榜单。它由Hugging Face 发布，评估LLM这几个基准数据集：小学科学、常识推理、多任务准确性、语言理解
2. CLUE 是中文LLM的通用评测榜单。它由北京大学发布，评估LLM这几个基准性数据集上的性能：中文回答、中文文档摘要、中文机器翻译、实体识别、词性标注、语义依存分析、阅读理解、推理
3. SuperGLUE： super General Language Understanding Evaluation 是一个多任务的自然语言理解NLU+的基准性测试，它结合了多个现有的NLU任务，如问答，文本蕴含，自然语言，以提供一个全面的评估 
4. GLUE：是SuperGLUE的前身，它包含了多个NLP任务，如问答，文本蕴含，情感分析等GLUE是评估语言模型在多种语言理解任务上表现的重要基准
5. BIG-Bench：是一个旨在评估大型语言模型在各种任务上表现的基准性测试，它包含了一系列的挑战性任务，如数学问题解决，逻辑推理和常识推理
6. WikiHop：是一个基于维基百科的问答任务，它要求模型从给定的文本中提取信息并回答问题，这个任务旨在评估模型的阅读理解和知识推理能力
7. HotpotQA：是一个问答任务，它要求模型从多个文档中找到答案，这个任务强调了模型在处理复杂信息检索和推理任务时的能力
8. XGLUE：是一个中文自然语言NLP+的基准性测试。它包含了多个任务，如文本匹配，命名实体识别，情感分析等，旨在评估模型在中文NLP任务上的性能
9. lmsys：是一个人类打分
10. ppp